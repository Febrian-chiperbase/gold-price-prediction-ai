{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj0fa6vwgj18/D7WihSWum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Febrian-chiperbase/gold-price-prediction-ai/blob/main/prediction_gold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x70RWni7gClM",
        "outputId": "7eec6a23-be43-40a4-aff2-2e6d22a80c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 46s]\n",
            "val_loss: 0.00473076431080699\n",
            "\n",
            "Best val_loss So Far: 0.0002859888190869242\n",
            "Total elapsed time: 02h 50m 34s\n",
            "\n",
            "    Hyperparameter terbaik yang ditemukan:\n",
            "    Units Layer 1: 32\n",
            "    Dropout Layer 1: 0.1\n",
            "    Bidirectional: False\n",
            "    Add LSTM Layer 2: False\n",
            "    Units Layer 2: N/A\n",
            "    Dropout Layer 2: N/A\n",
            "    Learning Rate: 0.01\n",
            "    \n",
            "Melatih model LSTM terbaik...\n",
            "Epoch 1/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0163 - val_loss: 0.0037\n",
            "Epoch 2/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 5.4770e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 9.6273e-04 - val_loss: 6.2798e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 8.4403e-04 - val_loss: 6.7543e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 8.1141e-04 - val_loss: 5.3183e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.3804e-04 - val_loss: 4.0755e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 6.3840e-04 - val_loss: 5.3979e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 6.6262e-04 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.0907e-04 - val_loss: 3.5818e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 5.6927e-04 - val_loss: 3.7931e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 5.2755e-04 - val_loss: 3.4431e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 5.3671e-04 - val_loss: 3.2758e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 4.7627e-04 - val_loss: 3.1635e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 5.0923e-04 - val_loss: 6.1200e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.8133e-04 - val_loss: 3.0802e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.7595e-04 - val_loss: 3.9304e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.5575e-04 - val_loss: 4.3460e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 4.9800e-04 - val_loss: 3.4214e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.5828e-04 - val_loss: 6.5935e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 4.5368e-04 - val_loss: 2.8524e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.9285e-04 - val_loss: 3.2416e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 4.5456e-04 - val_loss: 5.9425e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 5.0738e-04 - val_loss: 3.4164e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.3819e-04 - val_loss: 3.0636e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 4.6932e-04 - val_loss: 3.0078e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.9767e-04 - val_loss: 7.7373e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.6455e-04 - val_loss: 5.6690e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.5899e-04 - val_loss: 2.8334e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 4.2725e-04 - val_loss: 5.8186e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.4726e-04 - val_loss: 2.8182e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 4.7736e-04 - val_loss: 3.3280e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.5221e-04 - val_loss: 2.8534e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 4.2228e-04 - val_loss: 4.0061e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 5.5163e-04 - val_loss: 2.9146e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 4.7633e-04 - val_loss: 6.1252e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 4.2371e-04 - val_loss: 2.8425e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 4.1229e-04 - val_loss: 3.1511e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3.8443e-04 - val_loss: 3.8423e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.4315e-04 - val_loss: 2.9373e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 4.1916e-04 - val_loss: 4.0431e-04\n",
            "Pelatihan model terbaik selesai.\n",
            "Model disimpan di models_output/best_lstm_model.keras\n",
            "Plot history pelatihan disimpan sebagai images_output/lstm_terbaik_training_history.png\n",
            "\n",
            "--- Tahap 4: Evaluasi Model LSTM ---\n",
            "Membuat prediksi dengan LSTM multivariate...\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'slice' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-af74ad24035f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Tahap 4: Evaluasi Model LSTM ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_lstm_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mX_test_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_test_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         pred_train_lstm_unscaled, _ = predict_with_lstm_multivariate(\n\u001b[0m\u001b[1;32m    686\u001b[0m             \u001b[0mbest_lstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col_idx_lstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQUENCE_LENGTH_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-af74ad24035f>\u001b[0m in \u001b[0;36mpredict_with_lstm_multivariate\u001b[0;34m(model, X_data, scaler, target_col_index, num_features, sequence_length, future_steps, all_data_scaled)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m# --- PERBAIKAN BERDASARKAN ERROR: LHS dianggap (N,1) oleh NumPy saat error broadcast ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;31m# Maka, RHS juga harus (N,1). Menggunakan slice [:, start:end] untuk LHS juga memastikan LHS adalah 2D.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mdummy_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtarget_col_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_scaled_col_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;31m# --- Akhir Perbaikan ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'slice' and 'int'"
          ]
        }
      ],
      "source": [
        "# install_dependencies.sh (jalankan ini di terminal Linux Debian Anda sebelum menjalankan script Python)\n",
        "# sudo apt update\n",
        "# sudo apt install python3 python3-pip python3-venv build-essential python3-dev -y\n",
        "# python3 -m venv gold_env_v2\n",
        "# source gold_env_v2/bin/activate\n",
        "# pip install pandas numpy scikit-learn tensorflow keras-tuner prophet yfinance matplotlib\n",
        "!pip install keras-tuner\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt # Untuk Hyperparameter Tuning\n",
        "from prophet import Prophet\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import os # Untuk membuat direktori\n",
        "\n",
        "# Menonaktifkan logging INFO dari TensorFlow (opsional, untuk output yang lebih bersih)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "# Menonaktifkan logging INFO dari cmdstanpy (digunakan oleh Prophet)\n",
        "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
        "\n",
        "# --- 0. Konfigurasi dan Pembuatan Direktori ---\n",
        "IMAGES_DIR = \"images_output\"\n",
        "MODELS_DIR = \"models_output\"\n",
        "if not os.path.exists(IMAGES_DIR):\n",
        "    os.makedirs(IMAGES_DIR)\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.makedirs(MODELS_DIR)\n",
        "\n",
        "# --- 1. Pengumpulan Data ---\n",
        "def fetch_financial_data(ticker, start_date, end_date=None, name=\"Data\"):\n",
        "    \"\"\"Mengunduh data keuangan dari Yahoo Finance dan memastikan DatetimeIndex tunggal.\"\"\"\n",
        "    if end_date is None:\n",
        "        end_date = pd.to_datetime('today').strftime('%Y-%m-%d')\n",
        "    print(f\"Mengunduh {name} ({ticker}) dari {start_date} hingga {end_date}...\")\n",
        "    try:\n",
        "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "        if data.empty:\n",
        "            print(f\"Tidak ada data {name} yang diunduh untuk {ticker}.\")\n",
        "            return None\n",
        "\n",
        "        if isinstance(data.index, pd.MultiIndex):\n",
        "            print(f\"Data {name} ({ticker}) memiliki MultiIndex. Mencoba menyederhanakan...\")\n",
        "            data_reset = data.reset_index()\n",
        "\n",
        "            date_col_candidate = None\n",
        "            if 'Date' in data_reset.columns:\n",
        "                date_col_candidate = 'Date'\n",
        "            elif 'level_0' in data_reset.columns:\n",
        "                date_col_candidate = 'level_0'\n",
        "            else:\n",
        "                for col in data_reset.columns:\n",
        "                    if 'date' in str(col).lower():\n",
        "                        date_col_candidate = col\n",
        "                        break\n",
        "\n",
        "            if date_col_candidate:\n",
        "                try:\n",
        "                    data_reset[date_col_candidate] = pd.to_datetime(data_reset[date_col_candidate])\n",
        "                    data = data_reset.set_index(date_col_candidate)\n",
        "                    print(f\"Index untuk {name} ({ticker}) disederhanakan menggunakan kolom '{date_col_candidate}'.\")\n",
        "                except Exception as e_setidx:\n",
        "                    print(f\"Gagal menyederhanakan MultiIndex untuk {name} ({ticker}) menggunakan kolom '{date_col_candidate}': {e_setidx}\")\n",
        "                    return None\n",
        "            else:\n",
        "                print(f\"Tidak dapat menemukan kolom tanggal yang sesuai setelah mereset MultiIndex untuk {name} ({ticker}). Kolom: {data_reset.columns.tolist()}\")\n",
        "                return None\n",
        "        elif 'Date' in data.columns and not isinstance(data.index, pd.DatetimeIndex):\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'])\n",
        "                data = data.set_index('Date')\n",
        "            except Exception as e_setcol:\n",
        "                 print(f\"Gagal menjadikan kolom 'Date' sebagai index untuk {name} ({ticker}): {e_setcol}\")\n",
        "                 return None\n",
        "\n",
        "        if not isinstance(data.index, pd.DatetimeIndex):\n",
        "            try:\n",
        "                data.index = pd.to_datetime(data.index)\n",
        "            except Exception as e_conv_idx:\n",
        "                print(f\"Gagal mengonversi index yang ada menjadi DatetimeIndex untuk {name} ({ticker}): {e_conv_idx}\")\n",
        "                return None\n",
        "        data.index.name = 'Date'\n",
        "\n",
        "        print(f\"Data {name} ({ticker}) berhasil diunduh dan diproses. Index: {data.index.name}, Type: {type(data.index)}, nlevels: {data.index.nlevels}. Jumlah baris: {len(data)}\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error umum saat mengunduh data {name} ({ticker}): {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_and_merge_features(gold_df_input, economic_factors_config, start_date, end_date):\n",
        "    \"\"\"Memuat dan menggabungkan fitur harga emas dengan faktor ekonomi.\"\"\"\n",
        "    if gold_df_input is None or gold_df_input.empty:\n",
        "        print(\"Error: gold_df_input awal tidak valid atau kosong.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    gold_df = gold_df_input.copy()\n",
        "\n",
        "    if not isinstance(gold_df.index, pd.DatetimeIndex) or gold_df.index.nlevels > 1:\n",
        "        print(f\"Peringatan: gold_df di load_and_merge_features masih memiliki index bermasalah. Type: {type(gold_df.index)}, nlevels: {gold_df.index.nlevels}. Mencoba perbaikan lagi...\")\n",
        "        if isinstance(gold_df.index, pd.MultiIndex):\n",
        "            gold_df_reset = gold_df.reset_index()\n",
        "            date_col_candidate = None\n",
        "            if 'Date' in gold_df_reset.columns: date_col_candidate = 'Date'\n",
        "            elif 'level_0' in gold_df_reset.columns: date_col_candidate = 'level_0'\n",
        "            else:\n",
        "                for col in gold_df_reset.columns:\n",
        "                    if 'date' in str(col).lower(): date_col_candidate = col; break\n",
        "            if date_col_candidate:\n",
        "                try:\n",
        "                    gold_df_reset[date_col_candidate] = pd.to_datetime(gold_df_reset[date_col_candidate])\n",
        "                    gold_df = gold_df_reset.set_index(date_col_candidate)\n",
        "                except: pass\n",
        "\n",
        "        if not isinstance(gold_df.index, pd.DatetimeIndex):\n",
        "            try: gold_df.index = pd.to_datetime(gold_df.index)\n",
        "            except:\n",
        "                print(\"Gagal memastikan DatetimeIndex tunggal untuk gold_df di load_and_merge_features.\")\n",
        "                return pd.DataFrame()\n",
        "        gold_df.index.name = 'Date'\n",
        "        if gold_df.index.nlevels > 1:\n",
        "             print(f\"Masih MultiIndex pada gold_df setelah perbaikan di load_and_merge: {gold_df.index.names}\")\n",
        "             return pd.DataFrame()\n",
        "\n",
        "    if 'Close' not in gold_df.columns:\n",
        "        print(\"Error: Kolom 'Close' tidak ditemukan di gold_df setelah penyesuaian index.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    merged_df = gold_df[['Close']].copy()\n",
        "    merged_df.rename(columns={'Close': 'Gold_Close'}, inplace=True)\n",
        "\n",
        "    for factor_name, config in economic_factors_config.items():\n",
        "        factor_df = fetch_financial_data(config['ticker'], start_date, end_date, name=factor_name)\n",
        "        if factor_df is not None and not factor_df.empty and isinstance(factor_df.index, pd.DatetimeIndex) and factor_df.index.nlevels == 1:\n",
        "            column_to_use = config.get('column', 'Close')\n",
        "            if column_to_use in factor_df.columns:\n",
        "                temp_series = factor_df[column_to_use]\n",
        "                if not isinstance(temp_series, pd.Series):\n",
        "                    if isinstance(temp_series, pd.DataFrame) and temp_series.shape[1] == 1:\n",
        "                        temp_series = temp_series.iloc[:, 0]\n",
        "                    else:\n",
        "                        print(f\"Peringatan: factor_df['{column_to_use}'] untuk {factor_name} bukan Series tunggal. Dilewati.\")\n",
        "                        continue\n",
        "\n",
        "                temp_series.name = factor_name\n",
        "                factor_series_to_join = temp_series\n",
        "\n",
        "                try:\n",
        "                    merged_df = merged_df.join(factor_series_to_join, how='left')\n",
        "                except Exception as e_join:\n",
        "                    print(f\"Error saat join dengan {factor_name}: {e_join}\")\n",
        "                    print(\"Lanjutkan tanpa faktor ini.\")\n",
        "                    continue\n",
        "            else:\n",
        "                print(f\"Kolom '{column_to_use}' tidak ditemukan di data {factor_name}. Faktor ini dilewati.\")\n",
        "        else:\n",
        "            print(f\"Data untuk {factor_name} tidak tersedia, kosong, atau indexnya bermasalah. Faktor ini dilewati.\")\n",
        "\n",
        "    merged_df.ffill(inplace=True)\n",
        "    merged_df.bfill(inplace=True)\n",
        "    merged_df.dropna(inplace=True)\n",
        "\n",
        "    if merged_df.empty:\n",
        "        print(\"DataFrame kosong setelah penggabungan fitur dan penghapusan NaN.\")\n",
        "    elif 'Gold_Close' not in merged_df.columns:\n",
        "        print(\"Kolom 'Gold_Close' hilang setelah penggabungan. Periksa proses merge.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# --- 2. Pra-pemrosesan Data ---\n",
        "def preprocess_data_multivariate_lstm(data_df, target_column='Gold_Close', sequence_length=60):\n",
        "    \"\"\"Pra-pemrosesan data untuk model LSTM multivariate.\"\"\"\n",
        "    print(\"Melakukan pra-pemrosesan data untuk LSTM multivariate...\")\n",
        "    if data_df.empty or target_column not in data_df.columns:\n",
        "        print(f\"DataFrame kosong atau kolom target '{target_column}' tidak ditemukan.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data_df)\n",
        "\n",
        "    try:\n",
        "        target_col_index = data_df.columns.get_loc(target_column)\n",
        "    except KeyError:\n",
        "        print(f\"Kolom target '{target_column}' tidak ditemukan di data_df.columns.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(sequence_length, len(scaled_data)):\n",
        "        X.append(scaled_data[i-sequence_length:i, :])\n",
        "        y.append(scaled_data[i, target_col_index])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    if X.ndim == 2 and X.shape[0] > 0 :\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "    elif X.ndim == 1 and X.shape[0] > 0:\n",
        "        X = np.reshape(X, (1, X.shape[0], data_df.shape[1] if data_df.shape[1] > 0 else 1))\n",
        "\n",
        "    print(f\"Bentuk X: {X.shape}, Bentuk y: {y.shape}\")\n",
        "    if X.shape[0] == 0:\n",
        "        print(\"Tidak ada data yang dihasilkan setelah pra-pemrosesan. Periksa sequence_length atau panjang data.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    return X, y, scaler, target_col_index\n",
        "\n",
        "# --- 3. Model AI: LSTM ---\n",
        "class CustomHyperModel(kt.HyperModel):\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        use_bidirectional = hp.Boolean(\"use_bidirectional\", default=False)\n",
        "        hp_units_1 = hp.Int('units_1', min_value=32, max_value=256, step=32)\n",
        "        add_lstm_layer_2 = hp.Boolean(\"add_lstm_layer_2\", default=True)\n",
        "\n",
        "        return_sequences_layer1 = add_lstm_layer_2\n",
        "\n",
        "        if use_bidirectional:\n",
        "            model.add(Bidirectional(LSTM(units=hp_units_1, return_sequences=return_sequences_layer1),\n",
        "                                    input_shape=self.input_shape))\n",
        "        else:\n",
        "            model.add(LSTM(units=hp_units_1, return_sequences=return_sequences_layer1,\n",
        "                           input_shape=self.input_shape))\n",
        "        model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "        if add_lstm_layer_2:\n",
        "            hp_units_2 = hp.Int('units_2', min_value=32, max_value=128, step=32)\n",
        "            if use_bidirectional:\n",
        "                model.add(Bidirectional(LSTM(units=hp_units_2, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(LSTM(units=hp_units_2, return_sequences=False))\n",
        "            model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "        model.add(Dense(units=1))\n",
        "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                      loss='mean_squared_error')\n",
        "        return model\n",
        "\n",
        "def perform_hyperparameter_tuning(X_train, y_train, X_val, y_val, input_shape):\n",
        "    \"\"\"Melakukan hyperparameter tuning menggunakan KerasTuner.\"\"\"\n",
        "    print(\"Memulai Hyperparameter Tuning...\")\n",
        "    hypermodel = CustomHyperModel(input_shape)\n",
        "\n",
        "    tuner = kt.Hyperband(\n",
        "        hypermodel,\n",
        "        objective='val_loss',\n",
        "        max_epochs=30,\n",
        "        factor=3,\n",
        "        directory=os.path.join(MODELS_DIR, 'keras_tuner'),\n",
        "        project_name='gold_lstm_tuning_v3',\n",
        "        overwrite=True\n",
        "    )\n",
        "\n",
        "    stop_early = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "    tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[stop_early], verbose=1)\n",
        "\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "    print(f\"\"\"\n",
        "    Hyperparameter terbaik yang ditemukan:\n",
        "    Units Layer 1: {best_hps.get('units_1')}\n",
        "    Dropout Layer 1: {best_hps.get('dropout_1')}\n",
        "    Bidirectional: {best_hps.get('use_bidirectional')}\n",
        "    Add LSTM Layer 2: {best_hps.get('add_lstm_layer_2')}\n",
        "    Units Layer 2: {best_hps.get('units_2') if best_hps.get('add_lstm_layer_2') else 'N/A'}\n",
        "    Dropout Layer 2: {best_hps.get('dropout_2') if best_hps.get('add_lstm_layer_2') else 'N/A'}\n",
        "    Learning Rate: {best_hps.get('learning_rate')}\n",
        "    \"\"\")\n",
        "\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "    return model, best_hps\n",
        "\n",
        "def train_best_lstm_model(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):\n",
        "    \"\"\"Melatih model LSTM terbaik setelah tuning.\"\"\"\n",
        "    print(\"Melatih model LSTM terbaik...\")\n",
        "    stop_early = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                        validation_data=(X_val, y_val), callbacks=[stop_early], verbose=1)\n",
        "    print(\"Pelatihan model terbaik selesai.\")\n",
        "    try:\n",
        "        model.save(os.path.join(MODELS_DIR, \"best_lstm_model.keras\"))\n",
        "        print(f\"Model disimpan di {os.path.join(MODELS_DIR, 'best_lstm_model.keras')}\")\n",
        "    except Exception as e_save:\n",
        "        print(f\"Error saat menyimpan model: {e_save}\")\n",
        "    return model, history\n",
        "\n",
        "def predict_with_lstm_multivariate(model, X_data, scaler, target_col_index, num_features, sequence_length, future_steps=30, all_data_scaled=None):\n",
        "    \"\"\"Membuat prediksi menggunakan model LSTM multivariate.\"\"\"\n",
        "    print(\"Membuat prediksi dengan LSTM multivariate...\")\n",
        "\n",
        "    predictions_scaled = model.predict(X_data)\n",
        "\n",
        "    dummy_predictions = np.zeros((len(predictions_scaled), num_features))\n",
        "\n",
        "    # predictions_scaled seharusnya (N,1) dari Dense(1).\n",
        "    # Untuk assignment ke slice dummy_predictions[:, target_col_index] yang dianggap (N,1) oleh error,\n",
        "    # kita pastikan predictions_scaled adalah (N,1).\n",
        "    predictions_scaled_col_vector = predictions_scaled.reshape(-1, 1)\n",
        "\n",
        "    # --- PERBAIKAN BERDASARKAN ERROR: LHS dianggap (N,1) oleh NumPy saat error broadcast ---\n",
        "    # Maka, RHS juga harus (N,1). Menggunakan slice [:, start:end] untuk LHS juga memastikan LHS adalah 2D.\n",
        "    dummy_predictions[:, target_col_index:target_col_index+1] = predictions_scaled_col_vector\n",
        "    # --- Akhir Perbaikan ---\n",
        "\n",
        "    predictions = scaler.inverse_transform(dummy_predictions)[:, target_col_index]\n",
        "\n",
        "    future_predictions_list = []\n",
        "    if all_data_scaled is not None and future_steps > 0 and all_data_scaled.shape[0] >= sequence_length:\n",
        "        current_sequence = all_data_scaled[-sequence_length:].copy()\n",
        "\n",
        "        for _ in range(future_steps):\n",
        "            pred_input = current_sequence.reshape((1, sequence_length, num_features))\n",
        "            next_pred_scaled_target = model.predict(pred_input, verbose=0)[0,0]\n",
        "\n",
        "            new_row_scaled = current_sequence[-1, :].copy()\n",
        "            new_row_scaled[target_col_index] = next_pred_scaled_target\n",
        "\n",
        "            dummy_future_pred_row = np.zeros((1, num_features))\n",
        "            dummy_future_pred_row[0, target_col_index] = float(next_pred_scaled_target)\n",
        "            unscaled_future_pred_target = scaler.inverse_transform(dummy_future_pred_row)[0, target_col_index]\n",
        "            future_predictions_list.append(unscaled_future_pred_target)\n",
        "\n",
        "            current_sequence = np.append(current_sequence[1:,:], new_row_scaled.reshape(1, num_features), axis=0)\n",
        "\n",
        "    future_predictions_array = np.array(future_predictions_list).reshape(-1,1)\n",
        "    print(\"Prediksi masa depan LSTM multivariate selesai.\")\n",
        "    return predictions, future_predictions_array\n",
        "\n",
        "# --- 4. Model Terinspirasi Bayesian: Prophet ---\n",
        "def train_predict_prophet(data_df_input, target_column='Gold_Close', future_periods=30, test_size=0.2):\n",
        "    \"\"\"Melatih model Prophet dan membuat prediksi untuk target_column.\"\"\"\n",
        "    print(f\"Mempersiapkan data untuk Prophet (target: {target_column})...\")\n",
        "    if not isinstance(data_df_input, pd.DataFrame) or data_df_input.empty:\n",
        "        print(\"Error: data_df_input untuk Prophet bukan DataFrame yang valid atau kosong.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    df_prophet = data_df_input.copy()\n",
        "\n",
        "    if isinstance(df_prophet.index, pd.DatetimeIndex):\n",
        "        df_prophet = df_prophet.reset_index()\n",
        "\n",
        "    date_col_found = False\n",
        "    if 'Date' in df_prophet.columns and pd.api.types.is_datetime64_any_dtype(df_prophet['Date']):\n",
        "        df_prophet.rename(columns={'Date': 'ds'}, inplace=True)\n",
        "        date_col_found = True\n",
        "    elif 'index' in df_prophet.columns and pd.api.types.is_datetime64_any_dtype(df_prophet['index']):\n",
        "         df_prophet.rename(columns={'index': 'ds'}, inplace=True)\n",
        "         date_col_found = True\n",
        "\n",
        "    if not date_col_found and 'ds' not in df_prophet.columns :\n",
        "        print(f\"Error: Kolom tanggal (Date/index) tidak ditemukan atau bukan datetime untuk Prophet. Kolom: {df_prophet.columns.tolist()}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    if target_column not in df_prophet.columns:\n",
        "        print(f\"Error: Kolom target '{target_column}' tidak ditemukan untuk Prophet. Kolom: {df_prophet.columns.tolist()}\")\n",
        "        return None, None, None, None, None\n",
        "    df_prophet.rename(columns={target_column: 'y'}, inplace=True)\n",
        "\n",
        "    try:\n",
        "        df_prophet['y'] = pd.to_numeric(df_prophet['y'])\n",
        "        df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat konversi tipe data ds/y untuk Prophet: {e}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    df_prophet.dropna(subset=['ds', 'y'], inplace=True)\n",
        "    if df_prophet.empty:\n",
        "        print(\"Error: DataFrame untuk Prophet kosong setelah dropna ds/y.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    df_prophet_train_ready = df_prophet[['ds', 'y']]\n",
        "\n",
        "    train_size_prophet = int(len(df_prophet_train_ready) * (1 - test_size))\n",
        "    df_train_prophet = df_prophet_train_ready.iloc[:train_size_prophet]\n",
        "    df_test_prophet_actual_data_series_y = df_prophet_train_ready['y'].iloc[train_size_prophet:]\n",
        "\n",
        "    if df_train_prophet.empty or len(df_train_prophet) < 2:\n",
        "        print(f\"Error: Data training untuk Prophet tidak cukup (data: {len(df_train_prophet)}) atau kosong.\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    print(f\"Membangun dan melatih model Prophet dengan {len(df_train_prophet)} baris data training...\")\n",
        "    model_prophet = Prophet(interval_width=0.95, daily_seasonality=True)\n",
        "    try:\n",
        "        model_prophet.fit(df_train_prophet)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat Prophet fit: {e}\")\n",
        "        return None, None, None, None, None\n",
        "    print(\"Pelatihan Prophet selesai.\")\n",
        "\n",
        "    print(\"Membuat prediksi dengan Prophet...\")\n",
        "    periods_for_future_dates = len(df_test_prophet_actual_data_series_y) + future_periods\n",
        "    if periods_for_future_dates <= 0:\n",
        "        print(\"Tidak ada periode untuk prediksi masa depan Prophet.\")\n",
        "        return model_prophet, pd.DataFrame(columns=['ds', 'yhat', 'yhat_lower', 'yhat_upper']), pd.DataFrame(columns=['ds', 'yhat', 'yhat_lower', 'yhat_upper']), pd.DataFrame(columns=['ds', 'yhat', 'yhat_lower', 'yhat_upper']), pd.Series(dtype=float)\n",
        "\n",
        "    future_dates = model_prophet.make_future_dataframe(periods=periods_for_future_dates)\n",
        "    forecast = model_prophet.predict(future_dates)\n",
        "    print(\"Prediksi Prophet selesai.\")\n",
        "\n",
        "    forecast_test_period = forecast.iloc[train_size_prophet : len(df_prophet_train_ready)]\n",
        "    forecast_future_period = forecast.iloc[len(df_prophet_train_ready):]\n",
        "\n",
        "    return model_prophet, forecast, forecast_test_period, forecast_future_period, df_test_prophet_actual_data_series_y\n",
        "\n",
        "# --- 5. Evaluasi Model ---\n",
        "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
        "    y_true_np = np.array(y_true).ravel()\n",
        "    y_pred_np = np.array(y_pred).ravel()\n",
        "\n",
        "    if len(y_true_np) != len(y_pred_np):\n",
        "        print(f\"Peringatan evaluasi {model_name}: Panjang y_true ({len(y_true_np)}) dan y_pred ({len(y_pred_np)}) tidak sama.\")\n",
        "        min_len = min(len(y_true_np), len(y_pred_np))\n",
        "        if min_len == 0:\n",
        "             print(f\"Error evaluasi {model_name}: Tidak ada data yang cocok untuk dievaluasi.\")\n",
        "             return np.nan, np.nan\n",
        "        y_true_np = y_true_np[:min_len]\n",
        "        y_pred_np = y_pred_np[:min_len]\n",
        "\n",
        "    if len(y_true_np) == 0:\n",
        "        print(f\"Error evaluasi {model_name}: Tidak ada data untuk dievaluasi.\")\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true_np, y_pred_np))\n",
        "    mae = mean_absolute_error(y_true_np, y_pred_np)\n",
        "    print(f\"Evaluasi {model_name}:\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    return rmse, mae\n",
        "\n",
        "# --- 6. Visualisasi ---\n",
        "def plot_training_history(history, model_name=\"LSTM\"):\n",
        "    if history is None or history.history is None:\n",
        "        print(f\"Tidak ada history pelatihan untuk model {model_name}.\")\n",
        "        return\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if 'loss' in history.history:\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "    if 'val_loss' in history.history:\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'History Pelatihan Model {model_name}')\n",
        "    plt.ylabel('Loss (MSE)')\n",
        "    plt.xlabel('Epoch')\n",
        "    if 'loss' in history.history or 'val_loss' in history.history:\n",
        "        plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(IMAGES_DIR, f'{model_name.lower()}_training_history.png'))\n",
        "    print(f\"Plot history pelatihan disimpan sebagai {IMAGES_DIR}/{model_name.lower()}_training_history.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_predictions_multivariate(original_target_series, train_predict_plot, test_predict_plot, future_predict_plot,\n",
        "                                  model_name=\"LSTM\", title_suffix=\"\"):\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    if not isinstance(original_target_series.index, pd.DatetimeIndex):\n",
        "        try:\n",
        "            original_target_series_index = pd.to_datetime(original_target_series.index)\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting original_target_series.index to DatetimeIndex for plotting: {e}\")\n",
        "            original_target_series_index = original_target_series.index\n",
        "    else:\n",
        "        original_target_series_index = original_target_series.index\n",
        "\n",
        "    plt.plot(original_target_series_index, original_target_series.values, label='Harga Aktual Keseluruhan', color='blue', alpha=0.7)\n",
        "\n",
        "    plot_index = original_target_series_index\n",
        "\n",
        "    if train_predict_plot is not None and not np.all(np.isnan(train_predict_plot)):\n",
        "        if len(train_predict_plot) == len(plot_index):\n",
        "            plt.plot(plot_index, train_predict_plot,\n",
        "                    label=f'Prediksi {model_name} (Train)', color='orange', linestyle='--')\n",
        "        else:\n",
        "            print(f\"Peringatan: Panjang train_predict_plot ({len(train_predict_plot)}) tidak sama dengan plot_index ({len(plot_index)}). Plot training mungkin tidak akurat.\")\n",
        "\n",
        "    if test_predict_plot is not None and not np.all(np.isnan(test_predict_plot)):\n",
        "        if len(test_predict_plot) == len(plot_index):\n",
        "            plt.plot(plot_index, test_predict_plot,\n",
        "                    label=f'Prediksi {model_name} (Test)', color='red', linestyle='--')\n",
        "        else:\n",
        "             print(f\"Peringatan: Panjang test_predict_plot ({len(test_predict_plot)}) tidak sama dengan plot_index ({len(plot_index)}). Plot testing mungkin tidak akurat.\")\n",
        "\n",
        "    if future_predict_plot is not None and len(future_predict_plot) > 0:\n",
        "        last_date = None\n",
        "        if isinstance(plot_index, pd.DatetimeIndex) and not plot_index.empty:\n",
        "            last_date = plot_index[-1]\n",
        "\n",
        "        if last_date:\n",
        "            future_dates_idx = pd.to_datetime([last_date + pd.Timedelta(days=i) for i in range(1, len(future_predict_plot) + 1)])\n",
        "            plt.plot(future_dates_idx, future_predict_plot, label=f'Prediksi {model_name} (Masa Depan)', color='purple', linestyle=':')\n",
        "        else:\n",
        "            print(\"Tidak bisa membuat index tanggal untuk plot prediksi masa depan.\")\n",
        "\n",
        "    safe_title_suffix = title_suffix.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
        "    plt.title(f'Analisis Harga Emas Menggunakan {model_name}{title_suffix}')\n",
        "    plt.xlabel('Tanggal')\n",
        "    plt.ylabel('Harga Emas (Target)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    file_name_plot = f'gold_prediction_{model_name.lower()}{safe_title_suffix}.png'\n",
        "    plt.savefig(os.path.join(IMAGES_DIR, file_name_plot))\n",
        "    print(f\"Plot disimpan sebagai {IMAGES_DIR}/{file_name_plot}\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_prophet_forecast(model, forecast, original_data_prophet_ready_format, target_name=\"Emas (y)\"):\n",
        "    fig1 = model.plot(forecast)\n",
        "    plt.title(f'Prediksi Harga {target_name} Menggunakan Prophet')\n",
        "    plt.xlabel('Tanggal')\n",
        "    plt.ylabel(f'Harga {target_name}')\n",
        "    if 'ds' in original_data_prophet_ready_format.columns and 'y' in original_data_prophet_ready_format.columns:\n",
        "        plt.plot(original_data_prophet_ready_format['ds'], original_data_prophet_ready_format['y'], 'k.', label='Harga Aktual')\n",
        "    else:\n",
        "        print(\"Peringatan: Kolom 'ds' atau 'y' tidak ditemukan di data original untuk plot Prophet.\")\n",
        "    plt.legend()\n",
        "    safe_target_name = target_name.lower().replace(' (y)', '').replace('(', '_').replace(')', '').replace(' ', '_')\n",
        "    file_name_detail = f'prophet_prediction_{safe_target_name}_detail.png'\n",
        "    fig1.savefig(os.path.join(IMAGES_DIR, file_name_detail))\n",
        "    print(f\"Plot Prophet detail disimpan sebagai {IMAGES_DIR}/{file_name_detail}\")\n",
        "    plt.close(fig1)\n",
        "\n",
        "    fig2 = model.plot_components(forecast)\n",
        "    file_name_components = f'prophet_prediction_{safe_target_name}_components.png'\n",
        "    fig2.savefig(os.path.join(IMAGES_DIR, file_name_components))\n",
        "    print(f\"Plot komponen Prophet disimpan sebagai {IMAGES_DIR}/{file_name_components}\")\n",
        "    plt.close(fig2)\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Konfigurasi ---\n",
        "    GOLD_TICKER = 'GC=F'\n",
        "    TARGET_COLUMN_NAME = 'Gold_Close'\n",
        "    START_DATE = '2010-01-01'\n",
        "    END_DATE = None\n",
        "\n",
        "    ECONOMIC_FACTORS = {\n",
        "        'USD_Index': {'ticker': 'DX-Y.NYB', 'column': 'Close'},\n",
        "        'SP500': {'ticker': '^GSPC', 'column': 'Close'},\n",
        "        'US10Y_Treasury': {'ticker': '^TNX', 'column': 'Close'},\n",
        "    }\n",
        "\n",
        "    SEQUENCE_LENGTH_LSTM = 60\n",
        "    TRAIN_VAL_TEST_SPLIT_RATIO_TRAIN = 0.7\n",
        "    TRAIN_VAL_TEST_SPLIT_RATIO_VAL = 0.15\n",
        "\n",
        "    FUTURE_PREDICTION_DAYS = 30\n",
        "    DO_HYPERTUNING = True\n",
        "    DO_PROPHET_ANALYSIS = True\n",
        "\n",
        "    # 1. Pengumpulan dan Penggabungan Data\n",
        "    print(\"--- Tahap 1: Pengumpulan dan Penggabungan Data ---\")\n",
        "    gold_data_raw = fetch_financial_data(GOLD_TICKER, START_DATE, END_DATE, name=\"Emas\")\n",
        "\n",
        "    if gold_data_raw is None or gold_data_raw.empty:\n",
        "        print(\"Tidak bisa melanjutkan tanpa data harga emas. Program berhenti.\")\n",
        "        exit()\n",
        "\n",
        "    merged_full_df = load_and_merge_features(gold_data_raw, ECONOMIC_FACTORS, START_DATE, END_DATE)\n",
        "\n",
        "    if merged_full_df.empty or TARGET_COLUMN_NAME not in merged_full_df.columns:\n",
        "        print(f\"Data gabungan kosong atau kolom target '{TARGET_COLUMN_NAME}' tidak ada. Menggunakan data emas saja.\")\n",
        "        if 'Close' in gold_data_raw.columns:\n",
        "            merged_full_df = gold_data_raw[['Close']].copy()\n",
        "            if not isinstance(merged_full_df.index, pd.DatetimeIndex):\n",
        "                try:\n",
        "                    merged_full_df.index = pd.to_datetime(merged_full_df.index)\n",
        "                    merged_full_df.index.name = 'Date'\n",
        "                except Exception as e_idx_fallback:\n",
        "                    print(f\"Gagal konversi index fallback data emas: {e_idx_fallback}. Program berhenti.\")\n",
        "                    exit()\n",
        "            elif isinstance(merged_full_df.index, pd.DatetimeIndex):\n",
        "                 merged_full_df.index.name = 'Date'\n",
        "\n",
        "            merged_full_df.rename(columns={'Close': TARGET_COLUMN_NAME}, inplace=True)\n",
        "        else:\n",
        "            print(\"Kolom 'Close' juga tidak ditemukan di data emas mentah. Program berhenti.\")\n",
        "            exit()\n",
        "\n",
        "        if merged_full_df.empty:\n",
        "            print(\"Data emas fallback juga kosong. Program berhenti.\")\n",
        "            exit()\n",
        "\n",
        "    print(\"\\nData Gabungan (5 baris teratas):\")\n",
        "    print(merged_full_df.head())\n",
        "    print(f\"\\nJumlah fitur setelah digabung (termasuk target): {merged_full_df.shape[1]}\")\n",
        "    print(f\"Kolom data gabungan: {merged_full_df.columns.tolist()}\")\n",
        "    print(f\"Index merged_full_df: Name='{merged_full_df.index.name}', Type='{type(merged_full_df.index)}', Levels='{merged_full_df.index.nlevels}'\")\n",
        "\n",
        "\n",
        "    # 2. Pemisahan Data Train, Validation, Test SEBELUM Scaling\n",
        "    print(\"\\n--- Tahap 2: Pemisahan dan Pra-pemrosesan Data untuk LSTM ---\")\n",
        "    total_len = len(merged_full_df)\n",
        "    train_end_idx = int(total_len * TRAIN_VAL_TEST_SPLIT_RATIO_TRAIN)\n",
        "    val_end_idx = train_end_idx + int(total_len * TRAIN_VAL_TEST_SPLIT_RATIO_VAL)\n",
        "\n",
        "    train_df = merged_full_df.iloc[:train_end_idx]\n",
        "    val_df = merged_full_df.iloc[train_end_idx:val_end_idx]\n",
        "    test_df = merged_full_df.iloc[val_end_idx:]\n",
        "\n",
        "    print(f\"Ukuran set: Training={len(train_df)}, Validation={len(val_df)}, Test={len(test_df)}\")\n",
        "\n",
        "    if train_df.empty or val_df.empty :\n",
        "        print(\"Data training atau validation kosong setelah pemisahan. Periksa rasio split atau jumlah data awal.\")\n",
        "        exit()\n",
        "\n",
        "    X_train_lstm, y_train_lstm, scaler_lstm, target_col_idx_lstm = preprocess_data_multivariate_lstm(\n",
        "        train_df, target_column=TARGET_COLUMN_NAME, sequence_length=SEQUENCE_LENGTH_LSTM\n",
        "    )\n",
        "    if X_train_lstm is None or X_train_lstm.size == 0:\n",
        "        print(\"Gagal memproses data training untuk LSTM atau hasilnya kosong. Program berhenti.\")\n",
        "        exit()\n",
        "\n",
        "    val_df_aligned = val_df[train_df.columns]\n",
        "    scaled_val_data_full = scaler_lstm.transform(val_df_aligned)\n",
        "    X_val_lstm, y_val_lstm_list = [], []\n",
        "    if len(scaled_val_data_full) >= SEQUENCE_LENGTH_LSTM:\n",
        "        for i in range(SEQUENCE_LENGTH_LSTM, len(scaled_val_data_full)):\n",
        "            X_val_lstm.append(scaled_val_data_full[i-SEQUENCE_LENGTH_LSTM:i, :])\n",
        "            y_val_lstm_list.append(scaled_val_data_full[i, target_col_idx_lstm])\n",
        "        X_val_lstm = np.array(X_val_lstm)\n",
        "        y_val_lstm = np.array(y_val_lstm_list)\n",
        "        if X_val_lstm.ndim == 2 and X_val_lstm.size > 0: X_val_lstm = np.reshape(X_val_lstm, (X_val_lstm.shape[0], X_val_lstm.shape[1], 1))\n",
        "        print(f\"Data Validation LSTM: X_val: {X_val_lstm.shape}, y_val: {y_val_lstm.shape}\")\n",
        "    else:\n",
        "        print(\"Data validation tidak cukup untuk membuat sequence LSTM.\")\n",
        "        X_val_lstm, y_val_lstm = np.array([]), np.array([])\n",
        "\n",
        "    X_test_lstm, y_test_lstm = np.array([]), np.array([])\n",
        "    if not test_df.empty:\n",
        "        test_df_aligned = test_df[train_df.columns]\n",
        "        scaled_test_data_full = scaler_lstm.transform(test_df_aligned)\n",
        "\n",
        "        X_test_lstm_list_temp, y_test_lstm_list_temp = [], []\n",
        "        if len(scaled_test_data_full) >= SEQUENCE_LENGTH_LSTM:\n",
        "            for i in range(SEQUENCE_LENGTH_LSTM, len(scaled_test_data_full)):\n",
        "                X_test_lstm_list_temp.append(scaled_test_data_full[i-SEQUENCE_LENGTH_LSTM:i, :])\n",
        "                y_test_lstm_list_temp.append(scaled_test_data_full[i, target_col_idx_lstm])\n",
        "            X_test_lstm = np.array(X_test_lstm_list_temp)\n",
        "            y_test_lstm = np.array(y_test_lstm_list_temp)\n",
        "            if X_test_lstm.ndim == 2 and X_test_lstm.size > 0: X_test_lstm = np.reshape(X_test_lstm, (X_test_lstm.shape[0], X_test_lstm.shape[1], 1))\n",
        "            print(f\"Data Test LSTM: X_test: {X_test_lstm.shape}, y_test: {y_test_lstm.shape}\")\n",
        "        else:\n",
        "            print(\"Data test tidak cukup untuk membuat sequence LSTM.\")\n",
        "    else:\n",
        "        print(\"Test DataFrame kosong.\")\n",
        "\n",
        "    # 3. Pelatihan Model LSTM\n",
        "    print(\"\\n--- Tahap 3: Pelatihan Model LSTM ---\")\n",
        "    best_lstm_model = None\n",
        "    lstm_history = None\n",
        "    num_features_lstm = X_train_lstm.shape[2] if X_train_lstm.size > 0 and X_train_lstm.ndim == 3 else (merged_full_df.shape[1] if merged_full_df.shape[1] > 0 else 1)\n",
        "    input_shape_lstm = (SEQUENCE_LENGTH_LSTM, num_features_lstm)\n",
        "\n",
        "    if X_train_lstm.size > 0 and X_val_lstm.size > 0:\n",
        "        if DO_HYPERTUNING:\n",
        "            best_lstm_model_tuned, best_hps = perform_hyperparameter_tuning(X_train_lstm, y_train_lstm, X_val_lstm, y_val_lstm, input_shape_lstm)\n",
        "            best_lstm_model, lstm_history = train_best_lstm_model(best_lstm_model_tuned, X_train_lstm, y_train_lstm, X_val_lstm, y_val_lstm, epochs=100)\n",
        "        else:\n",
        "            model_path = os.path.join(MODELS_DIR, \"best_lstm_model.keras\")\n",
        "            if os.path.exists(model_path):\n",
        "                print(f\"Memuat model LSTM dari {model_path}...\")\n",
        "                best_lstm_model = tf.keras.models.load_model(model_path)\n",
        "            else:\n",
        "                print(\"Tidak ada model tersimpan. Membuat dan melatih model LSTM default (tanpa tuning)...\")\n",
        "                default_hp = kt.HyperParameters()\n",
        "                default_model_builder = CustomHyperModel(input_shape_lstm)\n",
        "                best_lstm_model = default_model_builder.build(default_hp)\n",
        "                best_lstm_model, lstm_history = train_best_lstm_model(best_lstm_model, X_train_lstm, y_train_lstm, X_val_lstm, y_val_lstm, epochs=50)\n",
        "\n",
        "        if lstm_history:\n",
        "            plot_training_history(lstm_history, model_name=\"LSTM_Terbaik\")\n",
        "    else:\n",
        "        print(\"Data training atau validation LSTM tidak cukup, pelatihan dilewati.\")\n",
        "\n",
        "    # 4. Evaluasi Model LSTM\n",
        "    print(\"\\n--- Tahap 4: Evaluasi Model LSTM ---\")\n",
        "    if best_lstm_model is not None and X_test_lstm.size > 0 and y_test_lstm.size > 0 :\n",
        "        pred_train_lstm_unscaled, _ = predict_with_lstm_multivariate(\n",
        "            best_lstm_model, X_train_lstm, scaler_lstm, target_col_idx_lstm,\n",
        "            num_features=num_features_lstm, sequence_length=SEQUENCE_LENGTH_LSTM, future_steps=0\n",
        "        )\n",
        "\n",
        "        all_data_scaled_for_future = scaler_lstm.transform(merged_full_df[train_df.columns])\n",
        "\n",
        "        pred_test_lstm_unscaled, future_preds_lstm_unscaled = predict_with_lstm_multivariate(\n",
        "            best_lstm_model, X_test_lstm, scaler_lstm, target_col_idx_lstm,\n",
        "            num_features=num_features_lstm,\n",
        "            sequence_length=SEQUENCE_LENGTH_LSTM,\n",
        "            future_steps=FUTURE_PREDICTION_DAYS,\n",
        "            all_data_scaled=all_data_scaled_for_future\n",
        "        )\n",
        "\n",
        "        dummy_y_test = np.zeros((len(y_test_lstm), num_features_lstm))\n",
        "\n",
        "        # --- PERBAIKAN EKSPLISIT ---\n",
        "        # y_test_lstm adalah 1D (N,), reshape ke (N,1) untuk assignment jika LHS dianggap demikian oleh error\n",
        "        y_test_lstm_col_vector = y_test_lstm.ravel().reshape(-1, 1)\n",
        "\n",
        "        # Mengassign (N,1) array ke slice kolom (N,1).\n",
        "        # dummy_y_test[:, target_col_idx_lstm:target_col_idx_lstm+1] adalah cara untuk mendapatkan slice (N,1)\n",
        "        dummy_y_test[:, target_col_idx_lstm:target_col_idx_lstm+1] = y_test_lstm_col_vector\n",
        "        # --- Akhir Perbaikan ---\n",
        "\n",
        "        y_test_lstm_unscaled = scaler_lstm.inverse_transform(dummy_y_test)[:, target_col_idx_lstm]\n",
        "\n",
        "        evaluate_model(y_test_lstm_unscaled, pred_test_lstm_unscaled, model_name=\"LSTM Test\")\n",
        "\n",
        "        original_target_series = merged_full_df[TARGET_COLUMN_NAME]\n",
        "\n",
        "        train_plot_lstm = np.full_like(original_target_series.values, np.nan, dtype=float)\n",
        "        train_plot_start_idx = SEQUENCE_LENGTH_LSTM\n",
        "        train_plot_end_idx = train_plot_start_idx + len(pred_train_lstm_unscaled)\n",
        "        if train_plot_end_idx <= len(train_plot_lstm) and train_plot_start_idx < len(train_plot_lstm):\n",
        "            train_plot_lstm[train_plot_start_idx:train_plot_end_idx] = pred_train_lstm_unscaled.ravel()\n",
        "\n",
        "        test_plot_lstm = np.full_like(original_target_series.values, np.nan, dtype=float)\n",
        "        plot_start_idx_for_test_preds = val_end_idx + SEQUENCE_LENGTH_LSTM\n",
        "\n",
        "        if len(pred_test_lstm_unscaled) > 0:\n",
        "            plot_end_idx_for_test_preds = plot_start_idx_for_test_preds + len(pred_test_lstm_unscaled)\n",
        "            if plot_end_idx_for_test_preds <= len(test_plot_lstm) and plot_start_idx_for_test_preds < len(test_plot_lstm):\n",
        "                test_plot_lstm[plot_start_idx_for_test_preds:plot_end_idx_for_test_preds] = pred_test_lstm_unscaled.ravel()\n",
        "            else:\n",
        "                 if plot_start_idx_for_test_preds < len(test_plot_lstm):\n",
        "                     can_fit = len(test_plot_lstm) - plot_start_idx_for_test_preds\n",
        "                     if can_fit > 0 and len(pred_test_lstm_unscaled.ravel()) >= can_fit :\n",
        "                        test_plot_lstm[plot_start_idx_for_test_preds:plot_start_idx_for_test_preds+can_fit] = pred_test_lstm_unscaled.ravel()[:can_fit]\n",
        "                        print(f\"Peringatan: Prediksi test LSTM dipotong agar muat ({can_fit} poin).\")\n",
        "                     elif can_fit > 0:\n",
        "                         print(f\"Peringatan: Prediksi test LSTM ({len(pred_test_lstm_unscaled.ravel())}) lebih pendek dari ruang yang tersedia ({can_fit}). Tidak diplot semua.\")\n",
        "                     else:\n",
        "                        print(\"Peringatan: Tidak ada ruang untuk plot prediksi test LSTM.\")\n",
        "                 else:\n",
        "                    print(f\"Peringatan: Indeks awal plot test LSTM ({plot_start_idx_for_test_preds}) di luar batas.\")\n",
        "\n",
        "        plot_predictions_multivariate(original_target_series, train_plot_lstm, test_plot_lstm,\n",
        "                                      future_preds_lstm_unscaled.ravel(),\n",
        "                                      model_name=\"LSTM\", title_suffix=\" dengan Faktor Ekonomi\")\n",
        "\n",
        "        print(f\"\\nPrediksi Harga {TARGET_COLUMN_NAME} Beberapa Hari ke Depan (LSTM):\")\n",
        "        last_actual_date_lstm = original_target_series.index[-1] if isinstance(original_target_series.index, pd.DatetimeIndex) else None\n",
        "        if last_actual_date_lstm:\n",
        "            for i, pred in enumerate(future_preds_lstm_unscaled.flatten()):\n",
        "                print(f\"  {(last_actual_date_lstm + pd.Timedelta(days=i+1)).strftime('%Y-%m-%d')}: {pred:.2f}\")\n",
        "        else:\n",
        "             for i, pred in enumerate(future_preds_lstm_unscaled.flatten()): print(f\"  Hari ke-{i+1}: {pred:.2f}\")\n",
        "    else:\n",
        "        print(\"Model LSTM tidak dilatih atau data test tidak cukup, evaluasi dan prediksi LSTM dilewati.\")\n",
        "\n",
        "    # 5. Analisis dengan Prophet (jika diaktifkan)\n",
        "    if DO_PROPHET_ANALYSIS:\n",
        "        print(\"\\n--- Tahap 5: Analisis dengan Prophet ---\")\n",
        "        prophet_input_df_main = merged_full_df[[TARGET_COLUMN_NAME]].copy()\n",
        "\n",
        "        prophet_test_ratio_from_split = len(test_df) / len(merged_full_df) if len(merged_full_df) > 0 else 0.2\n",
        "\n",
        "        if not prophet_input_df_main.empty:\n",
        "            prophet_results = train_predict_prophet(\n",
        "                prophet_input_df_main,\n",
        "                target_column=TARGET_COLUMN_NAME,\n",
        "                future_periods=FUTURE_PREDICTION_DAYS,\n",
        "                test_size = prophet_test_ratio_from_split\n",
        "            )\n",
        "\n",
        "            if prophet_results and prophet_results[0] is not None:\n",
        "                prophet_model, prophet_forecast, prophet_forecast_test_period, prophet_forecast_future_period, prophet_y_test_actual = prophet_results\n",
        "\n",
        "                if prophet_y_test_actual is not None and not prophet_y_test_actual.empty and \\\n",
        "                   prophet_forecast_test_period is not None and not prophet_forecast_test_period.empty:\n",
        "                    evaluate_model(prophet_y_test_actual.values, prophet_forecast_test_period['yhat'].values, model_name=\"Prophet (Test Period)\")\n",
        "                else:\n",
        "                    print(\"Data aktual atau prediksi test Prophet kosong/tidak valid, evaluasi dilewati.\")\n",
        "\n",
        "                original_data_prophet_plot = prophet_input_df_main.reset_index()\n",
        "                date_col_name_for_plot = 'Date'\n",
        "                if date_col_name_for_plot not in original_data_prophet_plot.columns and 'index' in original_data_prophet_plot.columns:\n",
        "                    date_col_name_for_plot = 'index'\n",
        "\n",
        "                original_data_prophet_plot.rename(columns={date_col_name_for_plot: 'ds', TARGET_COLUMN_NAME: 'y'}, inplace=True)\n",
        "\n",
        "\n",
        "                if prophet_forecast is not None and not prophet_forecast.empty and \\\n",
        "                   'ds' in original_data_prophet_plot and 'y' in original_data_prophet_plot:\n",
        "                     plot_prophet_forecast(prophet_model, prophet_forecast, original_data_prophet_plot[['ds','y']], target_name=TARGET_COLUMN_NAME)\n",
        "                else:\n",
        "                    print(\"Forecast Prophet atau data original untuk plot Prophet kosong/format salah, plotting dilewati.\")\n",
        "\n",
        "                if prophet_forecast_future_period is not None and not prophet_forecast_future_period.empty:\n",
        "                    print(f\"\\nPrediksi Harga {TARGET_COLUMN_NAME} Beberapa Hari ke Depan (Prophet):\")\n",
        "                    future_prophet_predictions = prophet_forecast_future_period[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
        "                    for index, row in future_prophet_predictions.iterrows():\n",
        "                        print(f\"  {row['ds'].strftime('%Y-%m-%d')}: Prediksi={row['yhat']:.2f} (Low: {row['yhat_lower']:.2f}, High: {row['yhat_upper']:.2f})\")\n",
        "                else:\n",
        "                    print(f\"Tidak ada prediksi masa depan {TARGET_COLUMN_NAME} dari Prophet.\")\n",
        "            else:\n",
        "                print(\"Gagal melatih atau membuat prediksi dengan Prophet.\")\n",
        "        else:\n",
        "            print(\"Data input untuk Prophet tidak valid atau kosong, analisis Prophet dilewati.\")\n",
        "\n",
        "    print(\"\\nAnalisis selesai.\")\n",
        "    print(f\"Plot disimpan di direktori: {IMAGES_DIR}\")\n",
        "    print(f\"Model LSTM (jika dilatih/disimpan) ada di direktori: {MODELS_DIR}\")"
      ]
    }
  ]
}